---
title: "Dummy data outline"
author: "Lars Murdock"
date: "2023-08-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objective

We're trying to create dummy data to use in the time series graphs for presentation work. The data is approved for extracted but we need to be careful about how and who we're sharing it. So for the purposes of demonstrating the functionality of the SNOMED code dashboard, we don't actually need to use real data.


It would be nice - and a good dev exercise - if the dummy data we create is plausible. We're not trying to imitate a particular timeseries (eg a specific SNOMED code or cluster), but certain aspects would make it more realistic. For example a time series with negative numbers wouldn't be plausible.

We can build this iteratively. Starting with the simplest time series, and not being too ambitious with the plausibility.

```{r}
# Create the time intervals (as an example i've just used years rather than mm-yyyy)
year_series <- c(1990:2021)

# Creating fake frequencies by sampling the normal distribution - and making there is a freq for each interval
basic_freq <- rnorm( length(year_series), 1000000, 50000)


fake_table <- cbind(year_series, basic_freq)
fake_table <- as.data.frame(fake_table)
colnames(fake_table) <- c("year", "freq")

head(fake_table)

```

You can see this is pretty low fidelity because frequencies are not whole numbers.


```{r}

plot(fake_table, type = "l", ylim = c(0, 1.2* max(fake_table$freq)) )


```

There are other characteristics in this graph that are less plausible, given most real time series do not start at 1990, and certainly not at full strength. 

Instead they'll begin in a more recent year, then increase and then plateau for the remaining time.



## Steps involved

We can map out the exercises we might want to attempt for this problem. As you can see they build iteratively.


1) generate a time series using rnorm (or similar if you find something better)
plot and check by-eye if this looks like the kind of fluctuation you see in actual time series

2) adjust if not (might want to set.seed for this process) once you're happy create a loop so you can generate multiple fake time series

3) some series represent large datasets, some smaller.... see if you can build this into your loop so they don't all have the same mean

4) some series start long ago (like 1990) some only starter in the last 4 years. See if you can build this characteristic into your loop

5) so far you've created time series... but we haven't tried to nest these (in the same way many snomed code time series make up one snomed cluster time series)... see if you can do this... then plot same as your coloured graphs

6) can we think of a way to mimic n vs n_distinct?

7) sense checks..... freq should never be below zero.... suppression.... every count should be round to the nearest 10


We've already achieved 1) in our demonstration purposed

### 2) Expanding to multiple time series


Context: Setting a seed

When using RNG or sampling, the randomness can be a problem. I might want to generate a number randomly... but should i happen to run the code again i may need/want to generate the same random number. By setting a seed we can make sure it starts with the same random number each time that seed is set. I've manually picked the seed '007'


```{r cars}

# without employing a set seed

print( rnorm( 5, 1000000, 50000))

print( rnorm( 5, 1000000, 50000))


# Now with a set seed

set.seed(007)
print( rnorm( 5, 1000000, 50000))

set.seed(007)
print( rnorm( 5, 1000000, 50000))


# It should be clear if you keep rerunning this chunk which change and which don't

```
Now lets try looping our first attempt so that we're generating multiple time series

```{r}
# Establishing parameters
year_series <- c(1990:2021)
number_of_series <- 5
set.seed(007)

# Creating fake frequencies by sampling the normal distribution - and making there is a freq for each interval

listofseries <- list()

for(n in c(1:number_of_series)){
  # creating the series same as before
  basic_freq <- rnorm( length(year_series), 1000000, 50000)
  fake_table <- cbind(year_series, basic_freq)
  fake_table <- as.data.frame(fake_table)
  # label it and the cols
  fake_table[3] <- paste0("dummySNOMEDcode", n)
  colnames(fake_table) <- c("year", "freq", "codename")
  head(fake_table)
  listofseries[[n]] <- fake_table

# now saving we've created a time series for a code and labelled it, we can save this to our list and move onto the next loop  
  
}

multipleCODEtable <- do.call("rbind", listofseries)
multipleCODEtable


```
We can plot these lines to see what they look like.


```{r}

library(ggplot2)

 ggplot(multipleCODEtable,  aes(x=year, y= freq, group=codename, color=codename)) +
    geom_line() + expand_limits(y=0)

```



```{r}

library(ggplot2)

options(scipen = 100, digits = 22)

ggplot(multipleCODEtable, aes(x=year, y=freq, fill= codename)) + 
    geom_area() 


```


If we were pretending each of these codes represented a cluster (as with line graph), then it'd be strange that they were very similarly common. 

If we were pretending each of these codes represented a code in a cluster (as with the stacked area chart), then again it'd be strange that they were all similarly common.

This is happening because each series can fluctuate, but they all have the same average.



### 3) Varying the size of the datasets

Some series represent large datasets, some smaller.... see if you can build this into your loop so they don't all have the same mean


```{r}
# Establishing parameters
year_series <- c(1990:2021)
number_of_series <- 5
set.seed(007)
# Here we randomly generate the averages
random_averages <- rnorm( number_of_series, 10000, 5000)*100

# Creating fake frequencies by sampling the normal distribution - and making there is a freq for each interval

listofseries <- list()

for(n in c(1:number_of_series)){
  # creating the series same as before
  basic_freq <- rnorm( length(year_series), random_averages[n], 50000)
  fake_table <- cbind(year_series, basic_freq)
  fake_table <- as.data.frame(fake_table)
  # label it and the cols
  fake_table[3] <- paste0("dummySNOMEDcode", n)
  colnames(fake_table) <- c("year", "freq", "codename")
  head(fake_table)
  listofseries[[n]] <- fake_table

# now saving we've created a time series for a code and labelled it, we can save this to our list and move onto the next loop  
  
}

multipleCODEtable <- do.call("rbind", listofseries)
multipleCODEtable


```


```{r}

library(ggplot2)

 ggplot(multipleCODEtable,  aes(x=year, y= freq, group=codename, color=codename)) +
    geom_line() + expand_limits(y=0)

```




```{r}

library(ggplot2)

options(scipen = 100, digits = 22)

ggplot(multipleCODEtable, aes(x=year, y=freq, fill= codename)) + 
    geom_area() 


```

This looks much more like the variety you see between clusters or within a cluster.

















